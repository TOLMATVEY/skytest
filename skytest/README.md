№1

Для хранения данных в DWH был выбран гибкий масштабируемый подход (DATA VAULT 2.0)
На ER-диаграмме (ERD-skyeng-export-2023-05-05) представлены все сопотствующие подходу компоненты (hub - Зеленые, link - голубые, satellite - оранжевые)
Хочу обратить внимание, что я не делал MD5 или SHA-1 хеш от описательных атрибутов, не выбирал суррогатные и бизнес ключи, 
не назначал индексы для ускорения джоинов и пр, так как по сути, это решение просто mvp.

№2

Почему Data Vault, а не скажем, Анкерная модель, снежинка и прочее?
Гибкость и расширяемость! Vault позволяет нам расширять структуры хранилища, а так же добавлять и сопоставлять данные из новых источников.
(Стоит оговориться, что я заметил teacher_id в одной из таблиц, вероятно, в скором будущем DWH немного расширится)
При этом, «сырые» данные и удобная структура их хранения позволяют нам сформировать витрину под любые требования.
(Опять оговорюсь,из-за обилия join-оф запросы могут быть быстрее, чем, скажем в денормализованных хранилищах)
Важным фактом выбора модели стало то, что Data Vault дает возможность реализовать версионность (что я и сделал).
А еще, если у нас возникнет еще несколько источников, хранилище мы все еще сможем наполнять параллельно, быстро и инкрементально.

№3

ETL процесс я реализовал на стороне Python. (Сделав допущение, что и в базе источнике и в хранилище стоит postgreSQL)
Все "распихано" по папкам, main.py основной скрипт (etl), log - файлик с логированием, в папке skyeng sqlscripts скрипты sql. main.cron - наш оркестр, ну и в py scripts лежит main.ddl - создание таблиц и my_decorator1 - самописные декораторы.
Инкрементальную загрузку SCD2 я реализовал так:
 
1. Очистка stage таблиц.

2. Захват данных из источника в stage. 
(чтобы захватить только необходимые данные, в main.ddl я добавил meta таблицу, сохраняющую время изменения в записи на стороне источника)

3. Загрузка в хранилище новых данных в источнике hub.
(Реализовал обычным left join where что-то null)

4. Загрузка в хранилище новых данных в источнике satellite.
(Принцип тот-же что и в п.4)

5. Загрузка в хранилище новых данных в источнике link

6. Обновление данных в satellite таблицах.
( Так как я реализовывал scd2, то сначала, я обновлял последнюю существующую запись, закрывая ее датой обновления записи 
в источнике, а затем добавлял новую, с открытой датой effective_to = '9999-12-31')

7. Удаление записи в satellite таблицах.
( Стоит сделать ремарку, я опять сделал допущение, что пока условный поток не удален, в поле deleted_at стоит null,
исходя из этого, я отлавливал "удаленца", добавлял его с открытой датой в таблицу, а затем изменял последнюю запись,
закрывая ее датой удаления.

8. Обновление данных  в таблице meta.

Я добавил достаточно синтаксического "сахара" в процесс.
Тут есть декораторы, логирование (в отделбную папку) и чат бот в телеграмм, который просигнализирует нам если загрузка не прошла.

№4

Витрина данных получилась странная, буду с вами откровенен.
Кроме информации о уроках, я добавил в нее крупицу информации по потокам, курсам и модулям ( флаги, не удалены ли они)



